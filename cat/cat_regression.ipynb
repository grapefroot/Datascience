{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_benchmark_data():\n",
    "    #data handling, take the input data, and merge them accordingly\n",
    "    #this is the original data handling routine of the xgb benchark script shared by Gilberto Titericz Junior\n",
    "    train = pd.read_csv('competition_data/train_set.csv', parse_dates=[2,])\n",
    "    test = pd.read_csv('competition_data/test_set.csv', parse_dates=[3,])\n",
    "    tube_data = pd.read_csv('competition_data/tube.csv')\n",
    "    bill_of_materials_data = pd.read_csv('competition_data/bill_of_materials.csv')\n",
    "    specs_data = pd.read_csv('competition_data/specs.csv')\n",
    "\n",
    "\n",
    "\n",
    "    train = pd.merge(train, tube_data, on ='tube_assembly_id')\n",
    "    train = pd.merge(train, bill_of_materials_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, tube_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, bill_of_materials_data, on ='tube_assembly_id')\n",
    "\n",
    "\n",
    "\n",
    "    # create some new features\n",
    "    train['year'] = train.quote_date.dt.year\n",
    "    train['month'] = train.quote_date.dt.month\n",
    "    #train['dayofyear'] = train.quote_date.dt.dayofyear\n",
    "    #train['dayofweek'] = train.quote_date.dt.dayofweek\n",
    "    #train['day'] = train.quote_date.dt.day\n",
    "\n",
    "    test['year'] = test.quote_date.dt.year\n",
    "    test['month'] = test.quote_date.dt.month\n",
    "    #test['dayofyear'] = test.quote_date.dt.dayofyear\n",
    "    #test['dayofweek'] = test.quote_date.dt.dayofweek\n",
    "    #test['day'] = test.quote_date.dt.day\n",
    "\n",
    "    # drop useless columns and create labels\n",
    "    idx = test.id.values.astype(int)\n",
    "    test = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\n",
    "    labels = train.cost.values\n",
    "\n",
    "    #'tube_assembly_id', 'supplier', 'bracket_pricing', 'material_id', 'end_a_1x', 'end_a_2x', 'end_x_1x', 'end_x_2x',\n",
    "    #  'end_a', 'end_x'\n",
    "    #for some reason material_id cannot be converted to categorical variable\n",
    "    train = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)\n",
    "\n",
    "    train['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    test['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    for i in range(1,9):\n",
    "        column_label = 'component_id_'+str(i)\n",
    "        # print(column_label)\n",
    "        train[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "        test[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "\n",
    "    train.fillna(0, inplace = True)\n",
    "    test.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "    # convert data to numpy array\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    # label encode the categorical variables\n",
    "    for i in range(train.shape[1]):\n",
    "        if i in [0,3,5,11,12,13,14,15,16,20,22,24,26,28,30,32,34]:\n",
    "            print(i,list(train[1:5,i]) + list(test[1:5,i]))\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[:,i]) + list(test[:,i]))\n",
    "            train[:,i] = lbl.transform(train[:,i])\n",
    "            test[:,i] = lbl.transform(test[:,i])\n",
    "\n",
    "    return train, test, idx, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle data routine in case you saved the data in a local environment\n",
    "def load_data(pickle_file):\n",
    "    load_file=open(pickle_file,'rb')\n",
    "    data=cPickle.load(load_file)\n",
    "    return  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# xgb learner, inline with the xgb benchmark script shared by Gilberto Titericz Junior\n",
    "def xgb_learning(labels, train, test, params):\n",
    "    label_log = np.log1p(labels)\n",
    "    # fit a random forest model\n",
    "    \n",
    "    plst = list(params.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train, label=label_log)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "\n",
    "    num_rounds = 500\n",
    "    # model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    # preds = model.predict(xgtest)\n",
    "\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    preds1 = model.predict(xgtest)\n",
    "    preds = np.expm1(preds1)\n",
    "\n",
    "    # I have commented out the follownig line for fast run time \n",
    "    # preds = model.predict(xgtest)\n",
    "    # n=1\n",
    "    # for loop in range(n):\n",
    "    #     model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    #     preds1 = preds1 + model.predict(xgtest)\n",
    "    # preds = np.expm1( preds1/(n+1))\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    linear=LinearRegression()\n",
    "    model=linear.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
    "        kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    model=clf.fit(train, label_log)\n",
    "\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=RandomForestRegressor(n_estimators=50, n_jobs=3)\n",
    "    model=clf.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params1 = {}\n",
    "params1[\"objective\"] = \"reg:linear\"\n",
    "params1[\"eta\"] = 0.1\n",
    "params1[\"min_child_weight\"] = 6\n",
    "params1[\"subsample\"] = 0.87\n",
    "params1[\"colsample_bytree\"] = 0.50\n",
    "params1[\"scale_pos_weight\"] = 1.0\n",
    "params1[\"silent\"] = 1\n",
    "params1[\"max_depth\"] = 7\n",
    "params1[\"seed\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params2 = {}\n",
    "params2['booster'] = 'gblinear'\n",
    "params2['objective'] = 'reg:linear'\n",
    "params2['min_shild_weight'] = 6\n",
    "params2['eta'] = 2\n",
    "params2['subsample'] = 0.85\n",
    "params2['colsample_bytree'] = 0.75\n",
    "params2['max_depth'] = 10\n",
    "params2['verbose'] = 1\n",
    "params2['scale_pos_weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066'])\n",
      "(3, ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'])\n",
      "(5, ['SP-0019', 'SP-0019', 'SP-0019', 'SP-0019', 'SP-0035', 'SP-0035', 'SP-0035', 'SP-0035'])\n",
      "(11, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(12, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(13, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(14, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(15, ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003'])\n",
      "(16, ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003'])\n",
      "(20, ['C-1312', 'C-1312', 'C-1312', 'C-1312', 'C-1622', 'C-1622', 'C-1622', 'C-1622'])\n",
      "(22, [' ', ' ', ' ', ' ', 'C-1629', 'C-1629', 'C-1629', 'C-1629'])\n",
      "(24, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(26, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(28, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(30, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(32, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(34, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "it takes 16.648 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    test_run=False\n",
    "    train, test, idx, labels=xgb_benchmark_data()\n",
    "\n",
    "    # if test run, then perform the cross validation\n",
    "    if test_run:\n",
    "        print(\"perform cross validation\")\n",
    "        rmse=[]\n",
    "        rnd_state=np.random.RandomState(1234)\n",
    "        for run in range(1, 11):\n",
    "            train_i, test_i = train_test_split(np.arange(train.shape[0]), train_size = 0.8, random_state = rnd_state )\n",
    "            tr_train=train[train_i]\n",
    "            tr_test=train[test_i]\n",
    "            tr_train_y=labels[train_i]\n",
    "            tr_test_y=labels[test_i]\n",
    "\n",
    "            # you can switch on/off each learninger as you wish by comment/uncomment\n",
    "            tr_preds=xgb_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=linear_learning(tr_train_y, tr_train, tr_test)\n",
    "            # tr_preds=svm_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=random_learning(tr_train_y, tr_train, tr_test)\n",
    "\n",
    "            rmse_score = (np.sum((np.log1p(tr_preds)-np.log1p(tr_test_y))**2)/len(test_i))**0.5\n",
    "            \n",
    "            #output test score with both real value and predicted price, this allow you to have a visual understand\n",
    "            #how close/far they are from each other\n",
    "            \n",
    "            compare=pd.DataFrame({\"tr_test_id\":test_i, \"cost_real\":tr_test_y, \"cost_pred\":tr_preds})\n",
    "            header=[\"tr_test_id\", \"cost_real\", \"cost_pred\"]\n",
    "            compare.to_csv('compare.csv', columns=header, index=False)\n",
    "            rmse.append(rmse_score)\n",
    "            print (\"logistic regression score for test run %i is %.6f\" %(run, rmse_score))\n",
    "        print (\"Mean logistic regression RMSE is %.6f:\" %np.mean(rmse))\n",
    "    else:\n",
    "        preds=xgb_learning(labels, train, test, params1)\n",
    "        preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "        preds.to_csv('xgb_test.csv', index=False)\n",
    "\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    print (\"it takes %.3f seconds\"  %(duration))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
