{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_benchmark_data():\n",
    "    #data handling, take the input data, and merge them accordingly\n",
    "    #this is the original data handling routine of the xgb benchark script shared by Gilberto Titericz Junior\n",
    "    train = pd.read_csv('competition_data/train_set.csv', parse_dates=[2,])\n",
    "    test = pd.read_csv('competition_data/test_set.csv', parse_dates=[3,])\n",
    "    tube_data = pd.read_csv('competition_data/tube.csv')\n",
    "    bill_of_materials_data = pd.read_csv('competition_data/bill_of_materials.csv')\n",
    "    specs_data = pd.read_csv('competition_data/specs.csv')\n",
    "\n",
    "\n",
    "\n",
    "    train = pd.merge(train, tube_data, on ='tube_assembly_id')\n",
    "    train = pd.merge(train, bill_of_materials_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, tube_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, bill_of_materials_data, on ='tube_assembly_id')\n",
    "\n",
    "\n",
    "\n",
    "    # create some new features\n",
    "    train['year'] = train.quote_date.dt.year\n",
    "    train['month'] = train.quote_date.dt.month\n",
    "    #train['dayofyear'] = train.quote_date.dt.dayofyear\n",
    "    #train['dayofweek'] = train.quote_date.dt.dayofweek\n",
    "    #train['day'] = train.quote_date.dt.day\n",
    "\n",
    "    test['year'] = test.quote_date.dt.year\n",
    "    test['month'] = test.quote_date.dt.month\n",
    "    #test['dayofyear'] = test.quote_date.dt.dayofyear\n",
    "    #test['dayofweek'] = test.quote_date.dt.dayofweek\n",
    "    #test['day'] = test.quote_date.dt.day\n",
    "\n",
    "    # drop useless columns and create labels\n",
    "    idx = test.id.values.astype(int)\n",
    "    test = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\n",
    "    labels = train.cost.values\n",
    "\n",
    "    #'tube_assembly_id', 'supplier', 'bracket_pricing', 'material_id', 'end_a_1x', 'end_a_2x', 'end_x_1x', 'end_x_2x',\n",
    "    #  'end_a', 'end_x'\n",
    "    #for some reason material_id cannot be converted to categorical variable\n",
    "    train = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)\n",
    "\n",
    "    train['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    test['material_id'].replace(np.nan,' ', regex=True, inplace= True)\n",
    "    for i in range(1,9):\n",
    "        column_label = 'component_id_'+str(i)\n",
    "        # print(column_label)\n",
    "        train[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "        test[column_label].replace(np.nan,' ', regex=True, inplace= True)\n",
    "\n",
    "    train.fillna(0, inplace = True)\n",
    "    test.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "    # convert data to numpy array\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    # label encode the categorical variables\n",
    "    for i in range(train.shape[1]):\n",
    "        if i in [0,3,5,11,12,13,14,15,16,20,22,24,26,28,30,32,34]:\n",
    "            print(i,list(train[1:5,i]) + list(test[1:5,i]))\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[:,i]) + list(test[:,i]))\n",
    "            train[:,i] = lbl.transform(train[:,i])\n",
    "            test[:,i] = lbl.transform(test[:,i])\n",
    "\n",
    "    return train, test, idx, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle data routine in case you saved the data in a local environment\n",
    "def load_data(pickle_file):\n",
    "    load_file=open(pickle_file,'rb')\n",
    "    data=cPickle.load(load_file)\n",
    "    return  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# xgb learner, inline with the xgb benchmark script shared by Gilberto Titericz Junior\n",
    "def xgb_learning(labels, train, test, params):\n",
    "    label_log = np.log1p(labels)\n",
    "    # fit a random forest model\n",
    "    \n",
    "    plst = list(params.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train, label=label_log)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "\n",
    "    num_rounds = 500\n",
    "    # model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    # preds = model.predict(xgtest)\n",
    "\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    preds1 = model.predict(xgtest)\n",
    "    preds = np.expm1(preds1)\n",
    "\n",
    "    # I have commented out the follownig line for fast run time \n",
    "    # preds = model.predict(xgtest)\n",
    "    # n=1\n",
    "    # for loop in range(n):\n",
    "    #     model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    #     preds1 = preds1 + model.predict(xgtest)\n",
    "    # preds = np.expm1( preds1/(n+1))\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    linear=LinearRegression()\n",
    "    model=linear.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
    "        kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    model=clf.fit(train, label_log)\n",
    "\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=RandomForestRegressor(n_estimators=50, n_jobs=3)\n",
    "    model=clf.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params1 = {}\n",
    "params1[\"objective\"] = \"reg:linear\"\n",
    "params1[\"eta\"] = 0.1\n",
    "params1[\"min_child_weight\"] = 6\n",
    "params1[\"subsample\"] = 0.87\n",
    "params1[\"colsample_bytree\"] = 0.50\n",
    "params1[\"scale_pos_weight\"] = 1.0\n",
    "params1[\"silent\"] = 1\n",
    "params1[\"max_depth\"] = 7\n",
    "params1[\"seed\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params2 = {}\n",
    "params2['booster'] = 'gblinear'\n",
    "params2['objective'] = 'reg:linear'\n",
    "params2['min_shild_weight'] = 6\n",
    "params2['eta'] = 2\n",
    "params2['subsample'] = 0.85\n",
    "params2['colsample_bytree'] = 0.75\n",
    "params2['max_depth'] = 10\n",
    "params2['verbose'] = 1\n",
    "params2['scale_pos_weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    test_run=True\n",
    "    train, test, idx, labels=xgb_benchmark_data()\n",
    "\n",
    "    # if test run, then perform the cross validation\n",
    "    if test_run:\n",
    "        print(\"perform cross validation\")\n",
    "        rmse=[]\n",
    "        rnd_state=np.random.RandomState(1234)\n",
    "        for run in range(1, 11):\n",
    "            train_i, test_i = train_test_split(np.arange(train.shape[0]), train_size = 0.8, random_state = rnd_state )\n",
    "            tr_train=train[train_i]\n",
    "            tr_test=train[test_i]\n",
    "            tr_train_y=labels[train_i]\n",
    "            tr_test_y=labels[test_i]\n",
    "            \n",
    "            \n",
    "            preds = []\n",
    "            # you can switch on/off each learninger as you wish by comment/uncomment\n",
    "            tr_preds_xgb = xgb_learning(tr_train_y, tr_train, tr_test, params1)\n",
    "            preds.append(tr_preds_xgb)\n",
    "            #tr_preds=linear_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=svm_learning(tr_train_y, tr_train, tr_test)\n",
    "            tr_preds_rf=random_learning(tr_train_y, tr_train, tr_test)\n",
    "            preds.append(tr_preds_rf)\n",
    "            tr_preds = sum(preds)/2\n",
    "            rmse_score = (np.sum((np.log1p(tr_preds)-np.log1p(tr_test_y))**2)/len(test_i))**0.5\n",
    "            \n",
    "            #output test score with both real value and predicted price, this allow you to have a visual understand\n",
    "            #how close/far they are from each other\n",
    "            \n",
    "            compare=pd.DataFrame({\"tr_test_id\":test_i, \"cost_real\":tr_test_y, \"cost_pred\":tr_preds})\n",
    "            header=[\"tr_test_id\", \"cost_real\", \"cost_pred\"]\n",
    "            compare.to_csv('compare.csv', columns=header, index=False)\n",
    "            rmse.append(rmse_score)\n",
    "            print (\"logistic regression score for test run %i is %.6f\" %(run, rmse_score))\n",
    "        print (\"Mean logistic regression RMSE is %.6f:\" %np.mean(rmse))\n",
    "    else:\n",
    "        preds=xgb_learning(labels, train, test, params1)\n",
    "        preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "        preds.to_csv('xgb_test.csv', index=False)\n",
    "\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    print (\"it takes %.3f seconds\"  %(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066'])\n",
      "(3, ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes'])\n",
      "(5, ['SP-0019', 'SP-0019', 'SP-0019', 'SP-0019', 'SP-0035', 'SP-0035', 'SP-0035', 'SP-0035'])\n",
      "(11, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(12, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(13, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(14, ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'])\n",
      "(15, ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003'])\n",
      "(16, ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003'])\n",
      "(20, ['C-1312', 'C-1312', 'C-1312', 'C-1312', 'C-1622', 'C-1622', 'C-1622', 'C-1622'])\n",
      "(22, [' ', ' ', ' ', ' ', 'C-1629', 'C-1629', 'C-1629', 'C-1629'])\n",
      "(24, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(26, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(28, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(30, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(32, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "(34, [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '])\n",
      "perform cross validation\n",
      "(12085,)\n",
      "(12085, 38)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-96780ea9de2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# you can switch on/off each learninger as you wish by comment/uncomment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mtr_preds_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_train_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_preds_xgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m#tr_preds=linear_learning(tr_train_y, tr_train, tr_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4c912fbdf790>\u001b[0m in \u001b[0;36mxgb_learning\u001b[1;34m(labels, train, test, params)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# preds = model.predict(xgtest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mpreds1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/grapefroot/anaconda/lib/python2.7/site-packages/xgboost-0.40-py2.7.egg/xgboost.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, early_stopping_rounds, evals_result)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/grapefroot/anaconda/lib/python2.7/site-packages/xgboost-0.40-py2.7.egg/xgboost.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid training matrix: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    test_run=True\n",
    "    train, test, idx, labels=xgb_benchmark_data()\n",
    "\n",
    "    # if test run, then perform the cross validation\n",
    "    if test_run:\n",
    "        print(\"perform cross validation\")\n",
    "        rmse=[]\n",
    "        rnd_state=np.random.RandomState(1234)\n",
    "        for run in range(1, 11):\n",
    "            train_i, test_i = train_test_split(np.arange(train.shape[0]), train_size = 0.8, random_state = rnd_state )\n",
    "            tr_train=train[train_i]\n",
    "            tr_test=train[test_i]\n",
    "            tr_train_y=labels[train_i]\n",
    "            tr_test_y=labels[test_i]\n",
    "            \n",
    "            stacking_train, stacking_test, stacking_train_y, stacking_test_y=train_test_split(tr_train, tr_train_y, train_size = 0.5, random_state = rnd_state)\n",
    "            \n",
    "            meta_features = random_learning(stacking_train_y, stacking_train, stacking_test)\n",
    "            \n",
    "            print np.shape(meta_features)\n",
    "            print np.shape(stacking_test)\n",
    "            \n",
    "        \n",
    "            \n",
    "            preds = []\n",
    "            # you can switch on/off each learninger as you wish by comment/uncomment\n",
    "            tr_preds_xgb = xgb_learning(tr_train_y, tr_train, tr_test, params1)\n",
    "            preds.append(tr_preds_xgb)\n",
    "            #tr_preds=linear_learning(tr_train_y, tr_train, tr_test)\n",
    "            #tr_preds=svm_learning(tr_train_y, tr_train, tr_test)\n",
    "            tr_preds_rf=random_learning(tr_train_y, tr_train, tr_test)\n",
    "            preds.append(tr_preds_rf)\n",
    "            tr_preds = sum(preds)/2\n",
    "            rmse_score = (np.sum((np.log1p(tr_preds)-np.log1p(tr_test_y))**2)/len(test_i))**0.5\n",
    "            \n",
    "            #output test score with both real value and predicted price, this allow you to have a visual understand\n",
    "            #how close/far they are from each other\n",
    "            \n",
    "            compare=pd.DataFrame({\"tr_test_id\":test_i, \"cost_real\":tr_test_y, \"cost_pred\":tr_preds})\n",
    "            header=[\"tr_test_id\", \"cost_real\", \"cost_pred\"]\n",
    "            compare.to_csv('compare.csv', columns=header, index=False)\n",
    "            rmse.append(rmse_score)\n",
    "            print (\"logistic regression score for test run %i is %.6f\" %(run, rmse_score))\n",
    "        print (\"Mean logistic regression RMSE is %.6f:\" %np.mean(rmse))\n",
    "    else:\n",
    "        preds=xgb_learning(labels, train, test, params1)\n",
    "        preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "        preds.to_csv('xgb_test.csv', index=False)\n",
    "\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    print (\"it takes %.3f seconds\"  %(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hstack in module numpy.core.shape_base:\n",
      "\n",
      "hstack(tup)\n",
      "    Stack arrays in sequence horizontally (column wise).\n",
      "    \n",
      "    Take a sequence of arrays and stack them horizontally to make\n",
      "    a single array. Rebuild arrays divided by `hsplit`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        All arrays must have the same shape along all but the second axis.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    concatenate : Join a sequence of arrays together.\n",
      "    hsplit : Split array along second axis.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to ``np.concatenate(tup, axis=1)``\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((2,3,4))\n",
      "    >>> np.hstack((a,b))\n",
      "    array([1, 2, 3, 2, 3, 4])\n",
      "    >>> a = np.array([[1],[2],[3]])\n",
      "    >>> b = np.array([[2],[3],[4]])\n",
      "    >>> np.hstack((a,b))\n",
      "    array([[1, 2],\n",
      "           [2, 3],\n",
      "           [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asanyarray([1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.asanyarray([[3,4], [5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
